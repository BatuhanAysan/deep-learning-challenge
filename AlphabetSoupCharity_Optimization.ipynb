{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1PS9mkcROG5_"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "\n",
        "# Drop the 'EIN' and 'NAME' columns\n",
        "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])"
      ],
      "metadata": {
        "id": "DSk6f4hKWyPE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine value counts\n",
        "application_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "print(application_counts)\n",
        "\n",
        "# Choose cutoff\n",
        "application_types_to_replace = application_counts[application_counts < 500].index\n",
        "\n",
        "# Replace with \"Other\"\n",
        "for app in application_types_to_replace:\n",
        "    application_df[\"APPLICATION_TYPE\"] = application_df[\"APPLICATION_TYPE\"].replace(app, \"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "print(application_df[\"APPLICATION_TYPE\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLTlDW44XEZw",
        "outputId": "10cac952-2fb8-4ee9-a97d-aa1e51957569"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPLICATION_TYPE\n",
            "T3     27037\n",
            "T4      1542\n",
            "T6      1216\n",
            "T5      1173\n",
            "T19     1065\n",
            "T8       737\n",
            "T7       725\n",
            "T10      528\n",
            "T9       156\n",
            "T13       66\n",
            "T12       27\n",
            "T2        16\n",
            "T25        3\n",
            "T14        3\n",
            "T29        2\n",
            "T15        2\n",
            "T17        1\n",
            "Name: count, dtype: int64\n",
            "APPLICATION_TYPE\n",
            "T3       27037\n",
            "T4        1542\n",
            "T6        1216\n",
            "T5        1173\n",
            "T19       1065\n",
            "T8         737\n",
            "T7         725\n",
            "T10        528\n",
            "Other      276\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine value counts\n",
        "classification_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "print(classification_counts)\n",
        "\n",
        "# Choose cutoff\n",
        "classifications_to_replace = classification_counts[classification_counts < 1000].index\n",
        "\n",
        "# Replace with \"Other\"\n",
        "for cls in classifications_to_replace:\n",
        "    application_df[\"CLASSIFICATION\"] = application_df[\"CLASSIFICATION\"].replace(cls, \"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "print(application_df[\"CLASSIFICATION\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MroH_ePyXWbC",
        "outputId": "f5d6cffa-75cc-41f5-ce3f-7e3c8157fad1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASSIFICATION\n",
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "         ...  \n",
            "C1248        1\n",
            "C6100        1\n",
            "C1820        1\n",
            "C1900        1\n",
            "C2150        1\n",
            "Name: count, Length: 71, dtype: int64\n",
            "CLASSIFICATION\n",
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "Other     2261\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply log transformation to ASK_AMT to reduce skewness\n",
        "import numpy as np\n",
        "application_df[\"ASK_AMT\"] = np.log1p(application_df[\"ASK_AMT\"])"
      ],
      "metadata": {
        "id": "snSXfDJwbuwF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the categorical variables\n",
        "application_df = pd.get_dummies(application_df).astype(int)\n",
        "\n",
        "# Split features (X) and target (y)\n",
        "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
        "y = application_df[\"IS_SUCCESSFUL\"].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaler = scaler.fit(X_train)\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "SLs5mQOSXcxo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Build the improved model\n",
        "nn = tf.keras.models.Sequential()\n",
        "nn.add(tf.keras.layers.Dense(units=64, activation=\"relu\", input_dim=X_train_scaled.shape[1]))\n",
        "nn.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
        "nn.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# EarlyStopping to prevent overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model (with validation split)\n",
        "fit_model = nn.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# fit_model = nn.fit(X_train_scaled, y_train, epochs=150, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr6_XP0nX0QP",
        "outputId": "7d3ea7bc-d464-4446-a795-e40809f47505"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6986 - loss: 0.5968 - val_accuracy: 0.7388 - val_loss: 0.5478\n",
            "Epoch 2/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.5560 - val_accuracy: 0.7370 - val_loss: 0.5520\n",
            "Epoch 3/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.5435 - val_accuracy: 0.7355 - val_loss: 0.5479\n",
            "Epoch 4/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.5516 - val_accuracy: 0.7362 - val_loss: 0.5443\n",
            "Epoch 5/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.5498 - val_accuracy: 0.7361 - val_loss: 0.5496\n",
            "Epoch 6/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.5444 - val_accuracy: 0.7364 - val_loss: 0.5488\n",
            "Epoch 7/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.5446 - val_accuracy: 0.7341 - val_loss: 0.5467\n",
            "Epoch 8/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.5512 - val_accuracy: 0.7386 - val_loss: 0.5447\n",
            "Epoch 9/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.5423 - val_accuracy: 0.7388 - val_loss: 0.5448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfiWC20VYEAk",
        "outputId": "587359ac-3885-4a85-f57d-d1ca1fa880f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - 2ms/step - accuracy: 0.7301 - loss: 0.5544\n",
            "Loss: 0.5544053912162781, Accuracy: 0.7301457524299622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.save(\"AlphabetSoupCharity_Optimization.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-m4KVH0aOlw",
        "outputId": "4465c4b0-9fff-4d4c-981c-5f568846bd1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bf84pcdShCgn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}